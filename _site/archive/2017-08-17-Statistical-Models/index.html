<!DOCTYPE html><html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="baidu-site-verification" content="x4U8lzh1X1" /><title>统计模型 - 游戏暂停</title><link href="https://fonts.googleapis.com/css?family=Lato:900|Work+Sans" rel="stylesheet"><link rel="stylesheet" href="/css/main.css"><title>统计模型 | 游戏暂停</title><meta name="generator" content="Jekyll v3.7.3" /><meta property="og:title" content="统计模型" /><meta property="og:locale" content="zh_CN" /><meta name="description" content="李家伟的博客。" /><meta property="og:description" content="李家伟的博客。" /><link rel="canonical" href="http://localhost:4000/archive/2017-08-17-Statistical-Models/" /><meta property="og:url" content="http://localhost:4000/archive/2017-08-17-Statistical-Models/" /><meta property="og:site_name" content="游戏暂停" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2017-09-01T18:50:00+01:00" /><meta name="twitter:card" content="summary" /><meta name="twitter:site" content="@tiewuz" /><script type="application/ld+json"> {"headline":"统计模型","dateModified":"2017-09-01T18:50:00+01:00","datePublished":"2017-09-01T18:50:00+01:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/archive/2017-08-17-Statistical-Models/"},"description":"李家伟的博客。","@type":"BlogPosting","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/favicon.ico"}},"url":"http://localhost:4000/archive/2017-08-17-Statistical-Models/","@context":"http://schema.org"}</script><script type="text/x-mathjax-config"> MathJax.Hub.Config({ tex2jax: { skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'], inlineMath: [ ['$','$'] ], displayMath: [ ['$$','$$'] ], processEscapes: true } });</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script></head><body style="background-color: rgb(255, 255, 255)"><script src="/js/theme.min.js"></script><header> <a href="/"><div class="home"></div></a></header><h1 class="post-headline">统计模型</h1><div>2017-09-01</div><p>这篇我们讨论<u>统计模型</u>，那么到底什么是<u>统计模型</u>？<u>统计模型</u>是一系列简化事实的分布。</p><p>为什么我们需要简化事实？以地图为例，如果地图越来越精细、越来越大，以至于它可以 1:1 地刻画现实世界，这张地图还有用吗？我们需要简化事实的模型帮助我们从复杂的数据里得到有用的信息，所谓<a href="https://scensci.wordpress.com/2012/12/14/big-data-or-pig-data/">数据越多模型越不重要</a>的说法非常可笑，而许多媒体（例如连线）还深深相信这是事实。</p><p>正如 George Box 所言，所有模型都是错的，但有些模型有用。</p><blockquote><p>All models are wrong, but some models are useful.</p></blockquote><h2 id="参数模型与非参数模型">参数模型与非参数模型</h2><p>什么是参数？假如有一个函数 f(x) = ax + b，a、b 不是自变量，我们需要给定 a、b 的值才能计算函数 f(x)，这里的 a、b 就是参数。在统计中，f(x) = ax + b 是我们选择的模型，a、b 参数通常是未知的，需要用样本分布的参数（estimator）估计（estimate）人口分布的参数（estimand）。</p><p>我们把<u>统计模型</u>分为两类，参数模型与非参数模型。参数模型（例如<u>正态分布</u>、<u>二项分布</u>）需要有限个的参数（例如均值、方差），非参数模型（例如 Bootstrap）需要无限个参数。这个分法不完全绝对，像半参数模型是把无限个的参数和有限个的参数分离来研究。</p><p>常理说参数越多、假设越少、适用范围更广，但记住「没有免费的午餐（No Free Lunch）」！这个定理告诉我们，不存在万能的模型（就像深度学习不一定可以解决一切机器学习的问题），具体情况需要具体分析，在使用<u>统计模型</u>前，一定要对数据进行探索性数据分析再套模型，如果效果不佳，再继续尝试，数据科学是不断往复尝试（iterative）的过程。</p><h2 id="概率密度函数与累积分布函数">概率密度函数与<u>累积分布函数</u></h2><p>我们使用<u>概率密度函数</u>（Probability Density Function, PDF）与<u>累积分布函数</u>（Cumulative Distribution Function, CDF）来描述连续型变量（continuous random variable）的概率分布，对于离散型变量（discrete random variable）的分布，使用的是概率质量函数（Probability Mass Function, PMF）与<u>累积分布函数</u>（Cumulative Distribution Function, CDF）来描述。</p><p>人口的身高可以看做是连续型变量，PDF 描述了身高在 (m, n) 区间的「可能性」，PDF 在 (m, n) 区间的面积（也就是积分）对应的就是身高在 (m, n) 区间的概率。但是，只取一点 m 不能得到身高 = m 的概率（积分为0），你应该取一个极小值 ε， (m-ε, m+ε) 区间的积分，才是身高 = m 的概率。</p><p><img src="https://raw.githubusercontent.com/iewaij/introDataScience/master/pics//PDF.png" alt="" /></p><p>而对于离散型变量，例如医院每天新生儿数目，你取 x = 5，就能在 PMF 上得到诞生 5 名新生儿的概率，这是 PDF 与 PMF 最大的区别。</p><p><img src="https://raw.githubusercontent.com/iewaij/introDataScience/master/pics//PMF.png" alt="" /></p><p>CDF 描述了 PDF、PMF 所覆盖的面积。在人口身高 CDF 上取 x = n，你得到的值是身高在 (0, n) 区间的概率（身高不可能是负数吧），如果你想知道身高在 (m, n) 区间的概率，你应该在人口身高 CDF 上取 x = n 和 x = m，对应的 f(n) - f(m)，就是身高在 (m, n) 区间的概率。</p><p><img src="https://raw.githubusercontent.com/iewaij/introDataScience/master/pics//CCDF.png" alt="" /></p><p><img src="https://raw.githubusercontent.com/iewaij/introDataScience/master/pics//DCDF.png" alt="" /></p><h2 id="二项分布">二项分布</h2><p>在说<u>二项分布</u>前，有必要说明什么是伯努利分布。伯努利分布描述的是单次、有两种结果（成功和失败）的随机事件的概率，例如抛一次硬币就是伯努利分布，因为结果可能是正面或者背面。<u>二项分布</u>则描述了多次（<script type="math/tex">n</script>次）伯努利分布的概率分布, 假设<script type="math/tex">p</script>是结果为正面的概率，<script type="math/tex">P(K = k)</script>表示抛<script type="math/tex">n</script>次硬币有<script type="math/tex">k</script>次为正面的概率。</p><p><script type="math/tex">P(K = k) = \frac {n!} {(n-k)! × k!} \times p^{k}(1-p)^{n-k}</script></p><p>由于期望值和方差是线性（linearity）的，因此可以用伯努利分布的<script type="math/tex">n</script>次叠加推导出<u>二项分布</u>的期望值和方差。</p><script type="math/tex; mode=display">E(X+Y)=E(X)+E(Y)\\ E(K)=p+p+...p+p=np</script><script type="math/tex; mode=display">Var(X+Y)=Var(X)+Var(Y)\\ Var(K)=p(1-p)+p(1-p)+...p(1-p)+p(1-p)=np(1-p)</script><h2 id="泊松分布">泊松分布</h2><p><u>二项分布</u>里事件发生的次数足够多、成功的概率很小时，就是泊松分布。医院平均每日新生儿数目为<script type="math/tex">\lambda</script>，每日出生<script type="math/tex">k</script>名新生儿的概率为多少呢？我们可以把一天里的时间分成<script type="math/tex">n</script>份事件（比如每秒为一份），每份事件有两种结果（有新生儿和没有新生儿），<script type="math/tex">n</script>足够大，每一份时间出生新生儿的概率<script type="math/tex">\frac{\lambda}{n}</script>足够小，我们就能引入自然常数 e，经过推导可得：</p><script type="math/tex; mode=display">P(K=k) = \frac{\lambda^{k}e^{-\lambda}}{k!}</script><p>泊松分布成立的条件是 n 足够大（事件次数足够多），<script type="math/tex">\lambda/n</script>（每次事件发生的概率）足够小。例如每天车祸发生次数，路上有很多的车，但每辆车发生车祸的概率又很小，这时候就适用于泊松分布。</p><h2 id="指数分布">指数分布</h2><p>指数分布的<u>概率密度函数</u>为<script type="math/tex">f(x) = \lambda e ^ {-\lambda x},\ x > 0</script>，<u>累积分布函数</u>为<script type="math/tex">F(x) = 1 - e ^ {-\lambda x}</script>，PDF 和 CDF 曲线如下。</p><p><img src="https://i.loli.net/2017/08/31/59a79a9a17c6d.png" alt="Screen Shot 2017-08-31 at 1.11.41 PM" /></p><p>指数分布是唯一具有<u>无记忆性</u>（memoryless property）的分布。</p><p>什么是无记忆性呢？一个例子是彩龄（买彩票的时间）和中彩票，中彩票的概率和你买彩票多少年无关，有人第一次买彩票就中奖，有人一辈子都中不了奖，中彩票的概率对应彩龄的分布就是指数分布。</p><p>设 t 为彩龄，甲是彩龄 a 年的老彩民，每天都买彩票，甲在 b 年后中彩的概率为 P(t&gt; a + b | t &gt; a)，乙是刚入门的新手，也每天买彩票，乙在 b 年后中彩的概率为 P(t&gt; b)，如果甲中彩的概率等于乙中彩的概率，P(t&gt; a + b | t &gt; a) = P(t&gt; b)，则无记忆性成立。</p><p><img src="https://i.loli.net/2017/09/01/59a942ace1c5e.png" alt="Screen Shot 2017-09-01 at 7.05.07 PM" /></p><p>以上证明了指数分布的<u>无记忆性</u>成立。指数分布的<u>无记忆性</u>来源于泊松过程，本篇笔记暂不讨论，可参考知乎的<a href="https://www.zhihu.com/question/36965252">简单讨论</a>。</p><h2 id="正态高斯分布">正态（高斯）分布</h2><p><u>正态分布</u>（Normal Distribution），也称高斯分布，应该是最有名、最普遍的分布了。<u>正态分布</u>的 PDF 接受两个参数：均值和方差，图像是个对称的钟形曲线，面积符合 68-95-99.7% 规则：在 ±一个标准差区间内，概率是 0.68，±两个标准差区间内，概率是 0.95，±三个标准差区间内，概率是 0.997。</p><p>既然指数分布具有<u>无记忆性</u>，那么<u>正态分布</u>有什么特点？一个特点是<u>正态分布</u>最大化交叉熵（entropy），交叉熵（entropy）描述了事物的随机、混乱程度，如果给定分布的均值和方差，<u>正态分布</u>使其交叉熵最大，也就是使其混乱程度最大。<u>正态分布</u>还有许多其他特点，比如中心极限定理，中心极限定理告诉我们，如果我们把大量的独立的随机变量加起来，其分布就是<u>正态分布</u>。比如说，我们扔无数次骰子，每次扔两个骰子并把点数相加，其点数的分布是近似的<u>正态分布</u>（如图所示），如果每次扔一百个骰子并把点数相加，点数的分布会更加光滑，也更加接近<u>正态分布</u>。而对于 p 接近 0.5 的泊松分布，也就是图像比较对称的泊松分布，也可以用<u>正态分布</u>近似。</p><p><img src="https://i.loli.net/2017/09/01/59a9391646b01.png" alt="12D7FFBC-27F7-44D1-B400-D4AF8A4CC578" /></p><p>大量的独立的随机变量相乘的结果，其分布通常就是<u>对数正态分布</u>（log Normal Distribution），其在金融和生物领域有很大用处。人口身高的分布是<u>正态分布</u>吗？不一定，因为影响身高的因素不是加起来的，不能说基因遗传导致你的身高加了 2 厘米、营养不良让你矮了 10 厘米，更可能是基因遗传导致你的身高多了 2%、营养不良让你矮了 10%。这种情况最好用对数（log）处理数据，用对数（log）处理也是个探索数据的好办法。<u>对数正态分布</u>就是说经过对数（log）处理后，其分布呈<u>正态分布</u>。</p><p>为什么<u>正态分布</u>是这样的？这需要强、弱大数定理和中心极限定理来解答，本篇笔记暂不讨论。</p><h2 id="bootstrap">Bootstrap</h2><p>如果中心极限定理不适用但需要验证样本估计的准确度怎么办？原因可能是样本数太少、需要估计的参数不适用等。比如我们有一份身高样本，可得到样本中位数预测人口身高的中位数，但中位数并不适用中心极限定理，我们怎么确定样本中位数能预测人口身高的中位数？预测的可信度又是多少？</p><p>这种情况下就可以使用 Bootstrap 方法，Bootstrap 方法就是在样本里允许重复随机取样，让样本自己生成「假样本」。比如说你的样本有 5 个数据，[1, 3, 4, 5, 8]，然后你从这 5 个数据里随机的取 5 个（允许重复），结果可能是 [4, 5, 4, 1, 8]，[8, 5, 8, 1, 4]… 等许多许多「假样本」，这时候你可以假装这些「假样本」是真的数据，然后对每个「假样本」取中位数，生成柱状图，来预测样本中位数和可信度。</p><p>听起来很不科学，但已经有无数的论文证明了 Bootstrap 是对的。一个解释是通过大数定理，当你对样本进行大量的随机取样，「假样本」的值会向真实值收敛，「假样本」是可以当做真样本使用的。</p><h2 id="深入阅读">深入阅读</h2><p><a href="https://book.douban.com/subject/4218659/">Statistical Models</a> <a href="https://book.douban.com/subject/4057698/">Statistical Models</a></p><br><br><div id="disqus_thread"></div><script defer> (function() { var d = document, s = d.createElement('script'); s.src = '//you-xi-zan-ting.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })();</script><noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript><script> (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','//www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-92264874-1', 'auto'); ga('send', 'pageview');</script></body></html>
